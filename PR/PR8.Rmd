---
title: "PR8"
author: "이유빈"
date: "2018년 11월 7일"
output: word_document
---

- 다음 영화 리뷰 크롤링
```{r}
#install.packages(c('httr','rvest'))
library(httr)
library(rvest)
```

```{r}
review=NULL     #값이 없는 변수 review 생성
star=NULL       #값이 없는 변수 star 생성
data=NULL       #값이 없는 변수 data 생성

for(i in 1:10){    #영화 아이디가 87215인 영화의 리뷰 1~10페이지를 읽는 코드이다.
  url<-c("http://movie.daum.net/moviedb/grade?movieId=87215&netizen&page=") 
  urls <- paste(url,i,sep = "")
  html_source = read_html(urls)    #저장된 url을 이용해 내용을 읽어 옴

  #review
  review0 = html_nodes(html_source,'p.desc_review') #F12 키를 이용해서 selector 확인 / html_nodes()를 이용하여 data 추출
  review1 = html_text(review0)   #html_text()를 이용하여 text만 추출
  review = append(review, review1)   #review라는 변수에 review1 text를 추가해라
  
  #rating
  star0 = html_nodes(html_source, 'em.emph_grade')    #F12 키를 이용해서 selector 확인 / html_nodes()를 이용하여 data 추출
  star1 = html_text(star0)   #html_text()를 이용하여 text만 추출
  star = append(star, star1)   #star라는 변수에 star1 text를 추가해라
  
  #data
  data0 = html_nodes(html_source, 'span.info_append')  #F12 키를 이용해서 selector 확인 / html_nodes()를 이용하여 data 추출
  data1 = html_text(data0)  #html_text()를 이용하여 text만 추출
  data = append(data,data1)  #data라는 변수에 data1 text를 추가해라
}

#merge
daum_m = data.frame(data, star, review) #data, star, review를 data.frame으로 만듦

#data - cleaning
daum_m[,1] = gsub("\n", "", daum_m[,1])  #data에서 \n을 삭제
daum_m[,1] = gsub("\r", "", daum_m[,1])  #data에서 \r을 삭제

#review - cleaning
daum_m[,3] = gsub("\r", "", daum_m[,3])  #review에서 \r을 삭제
daum_m[,3] = gsub("\n", "", daum_m[,3])  #review에서 \n을 삭제
daum_m[,3] = gsub("\t", "", daum_m[,3])  #review에서 \t를 삭제

write.csv(daum_m, file="movie_review.csv")  #daum_m을 "movie_review.csv"로 저장
```

# 연습문제
- 문제1: 위의 코드는 다음영화페이지 크롤링 코드입니다. 모든 코드의 주석을 상세히 달아주세요. 본인이 아는한 최대한 자세히 적어주세요.
- 문제2: 위의 코드는 날짜, 평점, 리뷰내용을 크롤링하고 있습니다. 다음영화페이지에서 그외의 데이터 중 크롤링이 가능한 것이 있으면 시도해보시기 바랍니다. 그리고 그 결과를 출력해주세요. 다음영화페이지가 아닌 다른 웹페이지의 내용을 크롤링하시면 더욱 좋습니다.
```{r}
#install.packages(c('httr','rvest'))
library(httr)
library(rvest)

title=NULL     #값이 없는 변수 title 생성
content=NULL       #값이 없는 변수 content 생성

for(i in 1:10){    #다음 뉴스에서 컬링에 대한 뉴스 추출
  url1<-c("https://search.daum.net/search?w=news&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=여자컬링+우승&p=")  #1부터 10페이지에 있는 뉴스
  url2 <- paste(url1,i,sep = "")
  html = read_html(url2)    #저장된 url을 이용해 내용을 읽어 옴

  #review
  title0 = html_nodes(html,'a.f_link_b') #F12 키를 이용해서 selector 확인 / html_nodes()를 이용하여 data 추출
  title1 = html_text(title0)   #html_text()를 이용하여 text만 추출
  title = append(title, title1)   #title라는 변수에 뉴스제목을 추가
  
  #rating
  content0 = html_nodes(html, 'p.f_eb.desc')    #F12 키를 이용해서 selector 확인 / html_nodes()를 이용하여 data 추출
  content1 = html_text(content0)   #html_text()를 이용하여 text만 추출
  content = append(content, content1)   #content라는 변수에 뉴스내용을 추가
}

news = data.frame(title,content)   #제목과 내용을 news라는 데이터프레임을 저장
write.csv(news, file="curling news.csv")  #데이터프레임을 csv파일로 저장
```
-문제3: 크롤링이 기업경영이나, 새로운 서비스 창출에 중요하게 사용된 사례를 찾고 소개해주세요.
```{r}
# <컨텐츠 마케팅>
# 컨덴츠 마케팅이란 "명확히 규정된 대상 고객을 유인, 유지하고 궁극적으로 회사에 이익을 가져오는 고객 행동을 독려하기 위해 가치 있고, 관련도 높으며, 지속적인 컨텐츠를 생산하고 확산하는 것에 초점을 맞춘 전략적인 마케팅적 접근법이다." 
# 컨텐츠 마케팅의 목표는 웹사이트 방문을 늘리거나 우리 제품에 대한 주목도를 획득하고, 구매전환율을 높여 궁극적으로 수익을 만들어내는 것이다.
# 컨텐츠의 유통이라는 관점에서 보면, 컨텐츠 마케팅은 블로그, SNS게시물, 웹페이지, 이메일, 팟캐스트, 동영상, 실시간 방송으로 구성되어 있다.
# 컨텐츠가 대상 고객이 관심을 갖는 것과 일치할 때에만, 고객들이 컨텐츠를 살펴볼 것이다.
# 마케팅 담당자들이 고객지향적인 정보 컨텐츠를 만들기 위해서 고객이 누구인지, 현재 인기있는 컨텐츠는 무엇인지, 시장의 트렌드는 어떠한지 등 데이터를 수집한다. 
# 컨텐츠 마케팅을 성공시키기 위해서는 컨텐츠의 높은 퀄리티 뿐만 아니라 적정한 시점과 정확한 채널에서 정확한 고객에서 정확한 내용을 전달하는 효과적인 유통 솔루션이 필요하다. 이 컨텐츠의 유통을 "컨테츠 마케팅 최종 단계에서의 승리"라고 표현한다.
#기업들은 자사의 컨텐츠를 유통하기 위해 6개의 채널(Email, Linkedin, YouTube, Print, Twitter, Print)을 활용한다.
# 오늘날 디지털 세상에서 기술의 발전은 기업에게 기회와 도전을 동시에 가져다 주었다. 마케팅 담당자들이 컨텐츠의 제작과 유통에 대해 효율성을 높이고자 데이터 수집 툴을 적극 활용할 필요가 있는 동시에, 기업은 컨텐츠 마케팅에 대한 지속적인 전략을 수립해야 한다.
```

# 도전문제
- 위의 코드는 for loop 내에서 i가 1부터 10까지만 동작합니다. 하지만 실제 영화리뷰가 10개만 있는 것은 아닙니다. 위의 코드와 수업시간에 학습하였던 CSS selector를 활용하여 실제 영화의 리뷰수만큼을 모두 크롤링할 수 있도록 만들어주세요.
```{r}
url_base<-"http://movie.daum.net/moviedb/grade?movieId=87215&netizen&page="
total_review =NULL

for(i in 1:829){    #영화 아이디가 87215인 영화의 전체리뷰를 읽는 코드이다.
  urls <- paste(url_base,i,sep = "")
  html_source = read_html(urls)    #저장된 urls을 이용해 내용을 읽어 옴

  #review
  review0 = html_nodes(html_source,'p.desc_review') #F12 키를 이용해서 selector 확인 / html_nodes()를 이용하여 data 추출
  review1 = html_text(review0)   #html_text()를 이용하여 text만 추출
  review = append(review, review1)   #review라는 변수에 review1 text를 추가해라
  
  #rating
  star0 = html_nodes(html_source, 'em.emph_grade')    #F12 키를 이용해서 selector 확인 / html_nodes()를 이용하여 data 추출
  star1 = html_text(star0)   #html_text()를 이용하여 text만 추출
  star = append(star, star1)   #star라는 변수에 star1 text를 추가해라
  
  #data
  data0 = html_nodes(html_source, 'span.info_append')  #F12 키를 이용해서 selector 확인 / html_nodes()를 이용하여 data 추출
  data1 = html_text(data0)  #html_text()를 이용하여 text만 추출
  data = append(data,data1)  #data라는 변수에 data1 text를 추가해라
  
  total_review=cbind(data,star,review)
}

#data - cleaning
total_review[,1] = gsub("\n", "", total_review[,1])  #data에서 \n을 삭제
total_review[,1] = gsub("\r", "", total_review[,1])  #data에서 \r을 삭제

#review - cleaning
total_review[,3] = gsub("\r", "", total_review[,3])  #review에서 \r을 삭제
total_review[,3] = gsub("\n", "", total_review[,3])  #review에서 \n을 삭제
total_review[,3] = gsub("\t", "", total_review[,3])  #review에서 \t를 삭제

write.csv(total_review, file="total_review.csv", row.names = F)  #daum_m을 "total_review.csv"로 저장
```
